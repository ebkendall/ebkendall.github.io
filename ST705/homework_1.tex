\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,color,float}
\usepackage{graphicx,psfrag,epsf}
\usepackage{natbib}


\setlength{\oddsidemargin}{.15in} 
\setlength{\textwidth}{6.25in}
\setlength{\topmargin}{-0.25in}
\setlength{\headheight}{-0.15in}
\setlength{\textheight}{8.9in} 

\linespread{1.25}


\title{ST 705 Linear models and variance components \\ 
        Homework problem set 1}


\begin{document}
\maketitle

\begin{enumerate}

\item Let $\{a_{1},\dots,a_{n}\}$ and $\{b_{1},\dots,b_{n}\}$ be sequences of real numbers.  Show that
\[
\min\{a_{i}\} + \min\{b_{i}\} \le \min\{a_{i} + b_{i}\} \le \min\{a_{i}\} + \max\{b_{i}\}.
\]

\item Use Jensen's inequality to establish the arithmetic-geometric mean inequality.  That is, show that if $a_{1},\dots,a_{n}$ are positive constants, then 
\[
\frac{1}{n}\sum_{i=1}^{n}a_{i} \ge \bigg(\prod_{i=1}^{n}a_{i}\bigg)^{\frac{1}{n}}.
\]

\item Let $x = (x_{1}, \dots, x_{p})' \in \mathbb{R}^{p}$.  Show that for $i \in \{1,\dots,p\}$,
\[
|x_{i}| \le \|x\|_{2} \le \|x\|_{1},
\]
where $\|\cdot\|_{1}$ and $\|\cdot\|_{2}$ are the $l_{1}$ and $l_{2}$ vector norms, respectively.

\item Prove that all norms on a finite-dimensional vector space $V$ over $\mathbb{C}$ are {\em equivalent}.  That is, show that for any two norms, say $\|\cdot\|_{a}$ and $\|\cdot\|_{b}$, defined on $V$, there exists real-valued positive constants $c_{1}$ and $c_{2}$ such that for every $x \in V$,
\[
c_{1}\|x\|_{b} \le \|x\|_{a} \le c_{2}\|x\|_{b}.
\]
\begin{enumerate}
\item First, show that it is without loss of generality to consider $\|\cdot\|_{b} = \|\cdot\|_{1}$.
\item Second, demonstrate that it suffices to only consider $x \in V$ with $\|x\|_{1} = 1$.
\item Next, prove that any norm $\|\cdot\|_{a}$ is a continuous function under $\|\cdot\|_{1}$-distance.
\item Finally, apply a result from calculus such as the Bolzano-Weierstrass theorem or the extreme value theorem to finish your argument that all norms on a finite-dimensional vector space are {\em equivalent}.
\end{enumerate}
This notion of {\em equivalence} is in reference to the fact that if a sequence is convergent in {\em some} norm, then it is convergent in {\em all} norms.  Note the assumption of a {\em finite}-dimensional vector space.

\item Let $U$ and $V$ be random variables.  Establish the following inequalities.
\begin{enumerate}
\item $P(|U+V| > a + b) \le P(|U| > a) + P(|V| > b)$ for every $a,b \ge 0$.
\item $P(|UV| > a) \le P(|U| > a/b) + P(|V| > b)$ for every $a \ge 0$ and $b > 0$.
\end{enumerate}

\item Prove the following theorem.  Let $V$ be a vector space and $B = \{u_{1},\dots,u_{n}\}$ be a subset of $V$.  Then $B$ is a basis if and only if each $v \in V$ can be expressed \textit{uniquely} as 
\[
v = a_{1}u_{1} + \cdots + a_{n}u_{n}
\] 
for some set of scalars $\{a_{1},\dots,a_{n}\}$.

\end{enumerate}






\end{document}