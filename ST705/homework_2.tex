\documentclass[11pt]{article}
\usepackage{amsmath,amssymb,color,float}
\usepackage{graphicx,psfrag,epsf}
\usepackage{natbib}


\setlength{\oddsidemargin}{.15in} 
\setlength{\textwidth}{6.25in}
\setlength{\topmargin}{-0.25in}
\setlength{\headheight}{-0.15in}
\setlength{\textheight}{8.9in} 

\linespread{1.25}


\title{ST 705 Linear models and variance components \\ 
        Homework problem set 2}


\begin{document}
\maketitle

\begin{enumerate}



\item Show that every eigenvalue of a real symmetric matrix is real.

\item Prove that the eigenvalues of an upper triangular matrix $M$ are the diagonal components of $M$.

\item Prove that a (square) matrix that is both orthogonal and upper triangular must be a diagonal matrix.

\item Show that the covariance function defined for $X, Y \in \mathbb{R}^{p}$ by
\[
\text{Cov}(X,Y) := E[(X - E(X))(Y - E(Y))']
\]
satisfies the following properties.  For random variables $X, Y, Z \in \mathbb{R}^{p}$ with finite covariance, and any $c \in \mathbb{R}$,
\begin{enumerate}
\item $\text{Cov}(X+Y,Z) = \text{Cov}(X,Z) + \text{Cov}(Y,Z)$
\item $\text{Cov}(cX,Y) = c\cdot \text{Cov}(X,Y)$
\item $\text{Cov}(X,Y)^{*} = \text{Cov}(Y,X)$
\item $\text{Cov}(X,X) \ge 0$ for all $X$, and $\text{Cov}(X,X) = 0$ implies that $X$ is constant a.s.
\end{enumerate}
Then, deduce that if $p = 1$ the covariance is an inner product over some (quotient) vector space, and if $p > 1$ the the function $f(X,Y) := \text{tr}\big(\text{Cov}(X,Y)\big)$ is an inner product.

\item Let $A \in \mathbb{R}^{p\times p}$ be symmetric.  Use the spectral decomposition of $A$ to show that 
\[
\sup_{x\in\mathbb{R}^{p}\setminus\{0\}} \frac{x'Ax}{x'x} = \lambda_{\max},
\]
where $\lambda_{\max}$ is the largest eigenvalue of $A$.  Observe that this is a special case of the Courant-Fischer theorem (see \verb1https://en.wikipedia.org/wiki/Min-max_theorem1).

\item Construct an $n\times n$ matrix $A$ such that $\lambda_{\max}(A) \ne \sup\limits_{v\ne0}\big\{\frac{v'Av}{v'v}\big\}$, where $\lambda_{\max}(\cdot)$ denotes the maximum eigenvalue of its argument.  Why does your counter example not violate the Courant-Fischer theorem?

\item Let $V$ be a convex subset of some vector space.  Recall that a function $f : V \to \mathbb{R}$ is said to be $convex$ if for every $x, y \in V$ and every $\lambda \in [0,1]$,
\[
f(\lambda x + (1-\lambda)y) \le \lambda f(x) + (1-\lambda) f(y).
\]
Show, by definition, that the sum of squared errors function
\[
Q(\beta) := \|Y - X\beta\|_{2}^{2}
\]
is convex.

\end{enumerate}






\end{document}